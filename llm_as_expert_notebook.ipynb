{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Clone the branch of the repository with the code to run llm-as-expert system evaluation"
      ],
      "metadata": {
        "id": "-d1q5Yijzwk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IBclDFonzgvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "741a6b03-2adc-43cd-838b-5944476d541e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_project_summarization'...\n",
            "remote: Enumerating objects: 2822, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 2822 (delta 25), reused 28 (delta 13), pack-reused 2770 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2822/2822), 40.54 MiB | 15.62 MiB/s, done.\n",
            "Resolving deltas: 100% (431/431), done.\n",
            "Updating files: 100% (75/75), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch feat/llm-as-expert-extension https://stefano-gamba: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@github.com/Marlowess/NLP_project_summarization.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go into the main folder of the repository"
      ],
      "metadata": {
        "id": "-tvCMRO10I8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/NLP_project_summarization/"
      ],
      "metadata": {
        "id": "wX_D_kKA0Epk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbefa7bd-5dfd-46eb-9626-f075515eb673"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_project_summarization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install modules"
      ],
      "metadata": {
        "id": "V6HLgjSY0UXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements --quiet"
      ],
      "metadata": {
        "id": "wTJJhpsP0P6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2837d8fc-db82-40b6-a73e-f0e869f8ae7b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
            "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can decide if to take the time to run all the scripts to generate the inputs for LLM-as-expert evaluation or if to run just the LLM-as-expert scripts using file previously generated by me with the other scripts and already saved in the repository**"
      ],
      "metadata": {
        "id": "HzbWbZhz77f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RUN SCRIPTS TO GENERATE INPUT FOR LLM-AS-EXPERT EVALUATION**"
      ],
      "metadata": {
        "id": "kS8vr9ET4V0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run this script to get the data in the proper format. It will save some files in the folder data/processed."
      ],
      "metadata": {
        "id": "hjEf9d1-0bJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/data_loading/data_processing.py"
      ],
      "metadata": {
        "id": "5sNhCkwZ0XXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "acbbd776-405d-44c3-e87c-c70c432e3151"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_project_summarization/glimpse/data_loading/data_processing.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sub_dataset.rename(columns={\"review\": \"text\", \"metareview\": \"gold\"}, inplace=True)\n",
            "/content/NLP_project_summarization/glimpse/data_loading/data_processing.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sub_dataset.rename(columns={\"review\": \"text\", \"metareview\": \"gold\"}, inplace=True)\n",
            "/content/NLP_project_summarization/glimpse/data_loading/data_processing.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sub_dataset.rename(columns={\"review\": \"text\", \"metareview\": \"gold\"}, inplace=True)\n",
            "/content/NLP_project_summarization/glimpse/data_loading/data_processing.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sub_dataset.rename(columns={\"review\": \"text\", \"metareview\": \"gold\"}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run this script to use just a sample of the data. It will save a csv file in data/sample folder. Change the path with the dataset you want to sample and the sample fraction you prefer"
      ],
      "metadata": {
        "id": "znTFPb5r0udp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_all_reviews_path = 'data/processed/all_reviews_2017.csv'\n",
        "sample_fraction = 0.2"
      ],
      "metadata": {
        "id": "qF9pAKOC07Qq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/data_sampling_test/data_sampling.py {processed_all_reviews_path} {sample_fraction}"
      ],
      "metadata": {
        "id": "9yFiSDB20ozx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79507a42-cbdf-454c-e699-0958f5512691"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling completed. File saved as samples.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Genarate extractive candidates from the sample. It will save a csv file in data/candidates folder."
      ],
      "metadata": {
        "id": "Uh3rBYAG1Uqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = \"data/sample/samples.csv\""
      ],
      "metadata": {
        "id": "VsBg_VhF1bAA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/data_loading/generate_extractive_candidates.py --dataset_path {sample_path}"
      ],
      "metadata": {
        "id": "nGCLdrPM1UQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3d9497b6-52c5-42bd-c21d-408fc27ce49c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "Loading dataset...\n",
            "Generating summaries...\n",
            "100% 301/301 [00:00<00:00, 1938.44it/s]\n",
            "Map: 100% 301/301 [00:00<00:00, 11067.35 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Optional: idem for abstractive candidates generation"
      ],
      "metadata": {
        "id": "avfQrBw12BT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/data_loading/generate_abstractive_candidates.py --dataset_path {sample_path}"
      ],
      "metadata": {
        "id": "yaVdc31j17np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Compute rsa scores for extractive candidates. It will generate a pickle file with the results in the folder called output. If you don't want to use files already generated by me in the repo, change the input path of the summaries with the proper one generated in the previous steps"
      ],
      "metadata": {
        "id": "ny0AW7H82L76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractive_candidates_path = \"data/candidates/extractive_sentences-_-samples-_-none-_-2025-02-12-16-15-13.csv\"\n",
        "abstractive_candidates_path = \"data/candidates/facebook_bart-large-cnn-_-samples-_-top_p_sampling-_-trimmed-_-2025-02-12-16-19-50.csv\""
      ],
      "metadata": {
        "id": "h_D2tZHz2YRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/src/compute_rsa.py --summaries {extractive_candidates_path}"
      ],
      "metadata": {
        "id": "1ugqiVZi2Lg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Idem for abstractive candidates. I didn't do it for our report"
      ],
      "metadata": {
        "id": "rup3wOcY4JuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/src/compute_rsa.py --summaries {abstractive_candidates_path}"
      ],
      "metadata": {
        "id": "po4sdqhZ4JVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Extract glimpse unique and speaker summary by concatenating the results of rsa score and create a dataset with cols 'id', 'summary', 'reviews' as input for llm-as-expert evaluation.\n",
        "It will generate a csv file into the data/evaluation folder.\n",
        "Change the pickle path with the proper path of the pickle file computed at the previous step. Repeat the step if you want to generate summaries also from abstractive candidates."
      ],
      "metadata": {
        "id": "U8oa-cMp47GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_out_path = 'output/..' # fill with proper path\n",
        "reviews_path = 'data/sample/samples.csv'"
      ],
      "metadata": {
        "id": "jMB7C8k847zj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/extract_glimpse_summaries.py --rsa_res {pickle_out_path} --reviews {reviews_path}"
      ],
      "metadata": {
        "id": "LY5jDglq7Aph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Generate summaries with baseline methods to compare them to summaries generated by glimpse. Change the name of the method you want to use. I used just lex-rank and LSA"
      ],
      "metadata": {
        "id": "lliR3oor7MQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "method_lr = \"lex-rank\"\n",
        "method_lsa = \"LSA\""
      ],
      "metadata": {
        "id": "bjnaQcMg8SP8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/baselines/sumy_baselines.py --method {method_lr}"
      ],
      "metadata": {
        "id": "3PatYpC57Lz1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/baselines/sumy_baselines.py --method {method_lsa}"
      ],
      "metadata": {
        "id": "x8K2ZfC59dLa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Generate a dataset in the same format 'id', 'summary', 'reviews' also for baseline methods. It will save it in a csv file in data/evaluation folder"
      ],
      "metadata": {
        "id": "MPcS6UQ18_Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_lex_rank_summaries_path = \"data/evaluation/reviews-_-lex-rank-_-sumy_1.csv\"\n",
        "baseline_LSA_summaries_path = \"data/evaluation/reviews-_-LSA-_-sumy_1.csv\""
      ],
      "metadata": {
        "id": "rmJJvrRA9BS5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/extract_baseline_summaries.py --summaries {baseline_lex_rank_summaries_path} --reviews {reviews_path}"
      ],
      "metadata": {
        "id": "3rzjBqO49AVl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/extract_baseline_summaries.py --summaries {baseline_LSA_summaries_path} --reviews {reviews_path}"
      ],
      "metadata": {
        "id": "y7UmPiMt--y3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Generate a dataset with the Seahorse evaluation for each summary and save it in a csv file in the data/evaluation folder"
      ],
      "metadata": {
        "id": "L6YVpIrD9p_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_egu_csv_path = \"data/evaluation/extractive_glimpse_unique_summaries.csv\"\n",
        "for q in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]:\n",
        "  !python glimpse/evaluate/evaluate_seahorse_metrics_samples.py --question {q} --batch_size 4 --summaries {summaries_egu_csv_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6v4hTL_O9nz0",
        "outputId": "5fc1098e-6f46-4c62-9368-e16a2e6e2b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rconfig.json:   0% 0.00/884 [00:00<?, ?B/s]\rconfig.json: 100% 884/884 [00:00<00:00, 4.27MB/s]\n",
            "2025-02-15 14:38:47.928957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739630328.316213    5113 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739630328.424454    5113 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 14:38:49.368706: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "pytorch_model.bin:   8% 398M/4.92G [00:03<00:35, 127MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 159, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 118, in main\n",
            "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map='auto', torch_dtype=torch.float16)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3805, in from_pretrained\n",
            "    resolved_archive_file = cached_file(\n",
            "                            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 403, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n",
            "    _download_to_tmp_and_move(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n",
            "    http_get(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 452, in http_get\n",
            "    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 820, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 1066, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 955, in read\n",
            "    data = self._raw_read(amt)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 879, in _raw_read\n",
            "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 862, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 473, in read\n",
            "    s = self.fp.read(amt)\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "config.json: 100% 884/884 [00:00<00:00, 3.93MB/s]\n",
            "2025-02-15 14:39:05.270978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739630345.296027    5206 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739630345.303290    5206 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 14:39:05.327024: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "pytorch_model.bin:  49% 2.39G/4.92G [00:23<00:24, 101MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 159, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 118, in main\n",
            "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map='auto', torch_dtype=torch.float16)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3805, in from_pretrained\n",
            "    resolved_archive_file = cached_file(\n",
            "                            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 403, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n",
            "    _download_to_tmp_and_move(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n",
            "    http_get(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 452, in http_get\n",
            "    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 820, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 1066, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 955, in read\n",
            "    data = self._raw_read(amt)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 879, in _raw_read\n",
            "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/response.py\", line 862, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 473, in read\n",
            "    s = self.fp.read(amt)\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "config.json: 100% 884/884 [00:00<00:00, 5.19MB/s]\n",
            "2025-02-15 14:39:41.688398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739630381.717169    5359 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739630381.727398    5359 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 14:39:41.757964: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "pytorch_model.bin:  11% 535M/4.92G [00:06<00:51, 84.5MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 159, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 118, in main\n",
            "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map='auto', torch_dtype=torch.float16)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3805, in from_pretrained\n",
            "    resolved_archive_file = cached_file(\n",
            "                            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 403, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n",
            "    _download_to_tmp_and_move(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n",
            "    http_get(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 455, in http_get\n",
            "    temp_file.write(chunk)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_seahorse_metrics_samples.py\", line 5, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 367, in <module>\n",
            "    from torch._C import *  # noqa: F403\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 216, in _lock_unlock_module\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RUN SCRIPTS FOR LLM-as-expert evaluation**"
      ],
      "metadata": {
        "id": "cupItO5P_bMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Perform pairwise evaluation: extractive glimpse unique vs extractive glimpse speaker. It will save a csv file with the picks in data/evaluation folder"
      ],
      "metadata": {
        "id": "t6zTcEuE-tF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_egu = 'extractive_glimpse_u'\n",
        "model_egs = 'extractive_glimpse_s'\n",
        "summaries_egu_path = 'data/evaluation/extractive_glimpse_unique_summaries.json'\n",
        "summaries_egs_path = 'data/evaluation/extractive_glimpse_speaker_summaries.json'"
      ],
      "metadata": {
        "id": "Cl2INcmY-kRW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py --summaries_a {summaries_egu_path} --summaries_b {summaries_egs_path} --model_a {model_egu} --model_b {model_egs}"
      ],
      "metadata": {
        "id": "kmH11LY1_PhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "78033e89-8275-458a-c977-a5bd4b4b9493"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py\", line 171, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py\", line 161, in main\n",
            "    evaluation = evaluate_summary(reviews, generated_summary_a, generated_summary_b, model_a, model_b)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py\", line 132, in evaluate_summary\n",
            "    response = openai.chat.completions.create(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\", line 863, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1283, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 960, in request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 996, in _request\n",
            "    response = self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 914, in send\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
            "    response = connection.handle_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
            "    return self._connection.handle_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
            "    ) = self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
            "    event = self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
            "    data = self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\", line 128, in read\n",
            "    return self._sock.recv(max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1295, in recv\n",
            "    return self.read(buflen)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1168, in read\n",
            "    return self._sslobj.read(len)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Perform pairwise evaluation: extractive glimpse unique vs lex-rank. It will save a csv file with the picks in data/evaluation folder"
      ],
      "metadata": {
        "id": "0Dwj7hcbAWaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_egu = 'extractive_glimpse_u'\n",
        "model_lr = 'lexrank'\n",
        "summaries_egu_path = 'data/evaluation/extractive_glimpse_unique_summaries.json'\n",
        "summaries_lr_path = 'data/evaluation/lex-rank.json'"
      ],
      "metadata": {
        "id": "TpHSVoYR_PP3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py --summaries_a {summaries_egu_path} --summaries_b {summaries_lr_path} --model_a {model_egu} --model_b {model_lr}"
      ],
      "metadata": {
        "id": "V8wFsJH1_PE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e4694e0d-2be2-4a73-9851-fb78f8da1710"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Traceback (most recent call last):\n",
            "object address  : 0x78ec9c0c73a0\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perform pairwise evaluation: extractive glimpse unique vs LSA. It will save a csv file with the picks in data/evaluation folder"
      ],
      "metadata": {
        "id": "lR1x0tfSAaeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_egu = 'extractive_glimpse_u'\n",
        "model_LSA = 'LSA'\n",
        "summaries_egu_path = 'data/evaluation/extractive_glimpse_unique_summaries.json'\n",
        "summaries_LSA_path = 'data/evaluation/LSA.json'"
      ],
      "metadata": {
        "id": "IetySqAm_O6Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py --summaries_a {summaries_egu_path} --summaries_b {summaries_LSA_path} --model_a {model_egu} --model_b {model_LSA}"
      ],
      "metadata": {
        "id": "_M1T7ty6AbBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "41519742-e792-4586-b4f0-a9ebbcecf8e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "1/98\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py\", line 171, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py\", line 161, in main\n",
            "    evaluation = evaluate_summary(reviews, generated_summary_a, generated_summary_b, model_a, model_b)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert_pairwise.py\", line 132, in evaluate_summary\n",
            "    response = openai.chat.completions.create(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\", line 863, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1283, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 960, in request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 996, in _request\n",
            "    response = self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 914, in send\n",
            "    response = self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
            "    response = connection.handle_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
            "    return self._connection.handle_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
            "    ) = self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
            "    event = self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
            "    data = self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\", line 128, in read\n",
            "    return self._sock.recv(max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1295, in recv\n",
            "    return self.read(buflen)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1168, in read\n",
            "    return self._sslobj.read(len)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Give score to extractive glimpse unique summaries for ability to summarize common and unique ideas. It will save a csv file with scores in data/evaluation folder"
      ],
      "metadata": {
        "id": "pw89kJRxBFrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discrim_eval_type = \"discriminativeness\"\n",
        "SH_like_eval_type = \"seahorse_like\""
      ],
      "metadata": {
        "id": "h_ttjvvWBN_O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py --summaries_by_documents {summaries_egu_path} --eval_type {discrim_eval_type} --model {model_egu}"
      ],
      "metadata": {
        "id": "BlLA76s0BGQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "551dce05-e806-4936-a368-0b8058da043b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/98\n",
            "2/98\n",
            "3/98\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py\", line 154, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py\", line 147, in main\n",
            "    evaluation = evaluate_summary(reviews, generated_summary, eval_type)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py\", line 126, in evaluate_summary\n",
            "    response = openai.chat.completions.create(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\", line 863, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1283, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 960, in request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 996, in _request\n",
            "    response = self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 914, in send\n",
            "    response = self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
            "    response = connection.handle_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
            "    return self._connection.handle_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 97, in handle_request\n",
            "    with Trace(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_trace.py\", line 55, in __exit__\n",
            "    def __exit__(\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Give score to extractive glimpse unique summaries following Seahorse metrics. It will save a csv file with scores in data/evaluation folder"
      ],
      "metadata": {
        "id": "1ditQCGwBGyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py --summaries_by_documents {summaries_egu_path} --eval_type {SH_like_eval_type} --model {model_egu}"
      ],
      "metadata": {
        "id": "54JeLutbBHZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a55ad18e-85eb-46b2-cc72-f9cf7516d5a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/98\n",
            "2/98\n",
            "3/98\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py\", line 154, in <module>\n",
            "    main()\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py\", line 147, in main\n",
            "    evaluation = evaluate_summary(reviews, generated_summary, eval_type)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/evaluate_llm_as_expert.py\", line 126, in evaluate_summary\n",
            "    response = openai.chat.completions.create(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\", line 863, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1283, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 960, in request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 996, in _request\n",
            "    response = self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 914, in send\n",
            "    response = self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
            "    response = connection.handle_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
            "    return self._connection.handle_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 134, in handle_request\n",
            "    with Trace(\"response_closed\", logger, request) as trace:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Create plots to visulize results saved in the output file of the evaluation step. Each script will create some pdf files in the folder called plots"
      ],
      "metadata": {
        "id": "VhJWse3xECI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discrim_score_vis_type = \"discrim_score\"\n",
        "pairwise_vis_type = \"pairwise\"\n",
        "SH_vis_type = \"seahorse_score\""
      ],
      "metadata": {
        "id": "q-NXB7QyECmC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "egu_vs_egs_pairwise_eval_path = \"data/evaluation/extractive_glimpse_u_vs_extractive_glimpse_s_pairwise_evaluation_dataset.csv\""
      ],
      "metadata": {
        "id": "FVZnolYhE6gN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py --evaluation_dataset {egu_vs_egs_pairwise_eval_path} --type {pairwise_vis_type} --model {model_egu} --model_b {model_egs}"
      ],
      "metadata": {
        "id": "w_h4_4TGEcub"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "egu_vs_lexrank_pairwise_eval_path = \"data/evaluation/extractive_glimpse_u_vs_lexrank_pairwise_evaluation_dataset.csv\""
      ],
      "metadata": {
        "id": "2ei3cPkTFEVV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py --evaluation_dataset {egu_vs_lexrank_pairwise_eval_path} --type {pairwise_vis_type} --model {model_egu} --model_b {model_lr}"
      ],
      "metadata": {
        "id": "21ZGG-cYEoYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e255d34e-a1ce-4c9d-9b5a-0ea3eb2b0e1b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "egu_vs_lsa_pairwise_eval_path = \"data/evaluation/extractive_glimpse_u_vs_lsa_pairwise_evaluation_dataset.csv\""
      ],
      "metadata": {
        "id": "a5V6Af1ZFKoO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py --evaluation_dataset {egu_vs_lsa_pairwise_eval_path} --type {pairwise_vis_type} --model {model_egu} --model_b {model_LSA}"
      ],
      "metadata": {
        "id": "N09UyXtCEo_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b590a614-7dbb-484f-b5a3-45d8f1d12cae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "egu_unique_common_score_eval_path = \"data/evaluation/extractive_glimpse_u_discriminativeness_evaluation_dataset.csv\""
      ],
      "metadata": {
        "id": "jk7H4mb0FQ5x"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py --evaluation_dataset {egu_unique_common_score_eval_path} --type {discrim_score_vis_type}  --model {model_egu}"
      ],
      "metadata": {
        "id": "Scl4GNw5EpnL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seahorse_like_eval_data_path = \"data/evaluation/extractive_glimpse_u_seahorse_like_evaluation_dataset.csv\"\n",
        "seahorse_eval_data_path = \"data/evaluation/extractive_glimpse_unique_summaries_SH_metrics.csv\""
      ],
      "metadata": {
        "id": "8azWaBeCGGPN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py --evaluation_dataset {seahorse_like_eval_data_path} --type {SH_vis_type} --seahorse_evaluation_dataset {seahorse_eval_data_path} --model {model_egu}"
      ],
      "metadata": {
        "id": "FPpwyw7yEqKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c458c07b-8160-4ac7-ea18-1f93e261e8c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:55: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(evaluation_df[metric_SH_like], label=f\"{metric_SH_like}_SH_like\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:56: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(seahorse_evaluation_df[metric_SH], label=f\"{metric_SH_like}_SH\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:55: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(evaluation_df[metric_SH_like], label=f\"{metric_SH_like}_SH_like\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:56: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(seahorse_evaluation_df[metric_SH], label=f\"{metric_SH_like}_SH\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:55: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(evaluation_df[metric_SH_like], label=f\"{metric_SH_like}_SH_like\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:56: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(seahorse_evaluation_df[metric_SH], label=f\"{metric_SH_like}_SH\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:55: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(evaluation_df[metric_SH_like], label=f\"{metric_SH_like}_SH_like\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:56: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(seahorse_evaluation_df[metric_SH], label=f\"{metric_SH_like}_SH\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:55: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(evaluation_df[metric_SH_like], label=f\"{metric_SH_like}_SH_like\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:56: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(seahorse_evaluation_df[metric_SH], label=f\"{metric_SH_like}_SH\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:55: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(evaluation_df[metric_SH_like], label=f\"{metric_SH_like}_SH_like\", shade=True, alpha=0.5)\n",
            "/content/NLP_project_summarization/glimpse/evaluate/evaluate_llm_as_expert/visualize_results.py:56: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(seahorse_evaluation_df[metric_SH], label=f\"{metric_SH_like}_SH\", shade=True, alpha=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5i1ml0MEwo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}